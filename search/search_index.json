{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ISCC - Content Identifiers # The ISCC (International Standard Content Code) is a modern, generic, and free content identifier: Motivation # The media industry is still mostly relying on identifiers that were originally designed for physical products such as printed books and magazines. However, traditional content identifiers (like ISBN, ISSN or ISRC) are managed centrally and fall short of the requirements for digital trade. Freely accessible standard identifiers , which are specifically designed to manage content in our digital century are a fundamental prerequisite for blockchain based transactions and sales activities in an increasingly heterogeneous media environment. With better identifiers for digital content, the entire ecosystem becomes more efficient. Key Differentiators # Existing Media Identifiers ISCC Content Identifier Centralized issuance Decentralized issuance Industry specific overspecialization Generic content identifier None or human curated semantics Algorithmic similarity & deduplication High management costs Low management costs High barrier of entry Low barrier of entry Not designed for blockchain storage Designed for and registered on blockchain How it works # ISCC identifiers are generated algorithmically from a basic set of metadata and the content itself. The ISCC does not have to be carried explicitly with the content because the content itself is the authority of the ISCC Code . The ISCC Code is a unique, hierarchically structured composite identifier. It is built from a generic and balanced mix of content-derived, locality-sensitive and similarity-preserving hashes generated from metadata and content. The latest version of these pages can be found at iscc.codes","title":"Overview"},{"location":"#iscc-content-identifiers","text":"The ISCC (International Standard Content Code) is a modern, generic, and free content identifier:","title":"ISCC - Content Identifiers"},{"location":"#motivation","text":"The media industry is still mostly relying on identifiers that were originally designed for physical products such as printed books and magazines. However, traditional content identifiers (like ISBN, ISSN or ISRC) are managed centrally and fall short of the requirements for digital trade. Freely accessible standard identifiers , which are specifically designed to manage content in our digital century are a fundamental prerequisite for blockchain based transactions and sales activities in an increasingly heterogeneous media environment. With better identifiers for digital content, the entire ecosystem becomes more efficient.","title":"Motivation"},{"location":"#key-differentiators","text":"Existing Media Identifiers ISCC Content Identifier Centralized issuance Decentralized issuance Industry specific overspecialization Generic content identifier None or human curated semantics Algorithmic similarity & deduplication High management costs Low management costs High barrier of entry Low barrier of entry Not designed for blockchain storage Designed for and registered on blockchain","title":"Key Differentiators"},{"location":"#how-it-works","text":"ISCC identifiers are generated algorithmically from a basic set of metadata and the content itself. The ISCC does not have to be carried explicitly with the content because the content itself is the authority of the ISCC Code . The ISCC Code is a unique, hierarchically structured composite identifier. It is built from a generic and balanced mix of content-derived, locality-sensitive and similarity-preserving hashes generated from metadata and content. The latest version of these pages can be found at iscc.codes","title":"How it works"},{"location":"concept/","text":"ISCC - Concept # The internet is shifting towards a network of decentralized peer-to-peer transactions. If we want our transactions on the emerging blockchain networks to be about content we need standardized ways to address content. Our transactions might be payments, attributions, reputation, certification, licenses or entirely new kinds of value transfer. All this will happen much faster and easier if we, as a community, can agree on how to identify content in a decentralized environment. This is the first draft of an open proposal to the wider content community for a common content identifier. We would like to share our ideas and spark a conversation with journalists, news agencies, content creators, publishers, distributors, libraries, musicians, scientists, developers, lawyers, rights organizations and all the other participants of the content ecosystem. Introduction # There are many existing standards for media identifiers serving a wide array of use cases. For example book publishing uses the ISBN , magazines have the ISSN , music industry has ISRC , film has ISAN and science has DOI - each of them serving a set of specific purposes. These identifiers have important roles across many layers. The structure and management of these global identifiers strongly correlates with the grade of achievable automation and potential for innovation within and across different sectors of the media industries. Some communities, like online journalism, don't even have any global persistent identifiers for their content. Many of the established standards manage registration of identifiers in centralized or hierarchical systems involving manual and costly processes. Often the associated metadata is not easily or freely accessible for third parties (if available at all). The overhead, cost and general properties of these systems make them unsuitable for many innovative use cases. Existing and established standards have trouble keeping up with the fast evolving digital economy. For example nowadays major e-book retailers do not even require an ISBN and instead establish their own proprietary identifiers. Amazon has the ASIN , Apple has Apple-ID and Google has GKEY . The fast paced development of the digital media economy has led to an increasing fragmentation of identifiers and new barriers in interoperability. For many tasks current systems need to track and match all the different vendor specific IDs, which is an inefficient and error prone process. Advances in data structures, algorithms, machine learning and the uprise of crypto economics allows us to invent new kinds of media identifiers and re-imagine existing identifiers with innovative use cases in mind. Blockchains and Smart Contracts offer great opportunities in solving many of the challenges of identifier registration, like centralized management, data duplication and disambiguation, vendor lock-in and long term data retention. This is an open proposal to the digital media community and explores the possibilities of a decentralized content identifier system. We\u2019d like to establish an open standard for persistent, unique, vendor independent and content derived cross-media identifiers that are stored and managed in a global and decentralized blockchain. We envision a self-governing ecosystem with a low barrier of entry where commercial and non-commercial initiatives can both innovate and thrive next to each other. Media Identifiers for Blockchains # Media cataloging systems tend to get out of hand and become complex and often unmanageable. Our design proposal is focused on keeping the ISCC system as simple and more importantly as automatable as possible, while maximizing practical value for the most important use cases \u2014 meaning you should get out more than you have to put in. With this in mind we come to the following basic design decisions: A \u201cMeaningful\u201d Identifier # In traditional database systems it is recommended practice to work with surrogate keys as identifiers. A surrogate key has no business meaning and is completely decoupled from the data it identifies. Uniqueness of such identifiers is guaranteed either via centralized incremental assignment by the database system or via random UUIDs which have a very low probability of collisions. While random UUIDs could be generated in a decentralized way, both approaches require some external authority that establishes or certifies the linkage between the identifier and the associated metadata and content. This is why we decided to go with a \u201cmeaningful\u201d content and metadata derived identifier (CMDI) . Anyone will be able to verify that a specific identifier indeed belongs to a given digital content. Even better, anyone can \u201cfind\u201d the identifier for a given content without the need to consult external data sources. This approach also captures essential information about the media in the identifier itself, which is very useful in scenarios of machine learning and data analytics. A Decentralized Identifier # We would like our identifier to be registry agnostic. This means that identifiers can be self-issued in a decentralized and parallel fashion without the need to ask for permission. Even if identifiers are not registered in a central database or on a public blockchain they are still useful in cases where multiple independent parties exchange information about content. The CMDI approach is helpful with common issues like data integrity, validation, de-duplication and disambiguation. Storage Considerations # On a typical public blockchain all data is fully replicated among participants. This allows for independent and autonomous validation of transactions. All blockchain data is highly available, tamper-proof and accessible for free. However, under high load the limited transaction capacity (storage space per unit of time) creates a transaction fee market. This leads to growing transaction costs and makes storage space a scarce and increasingly precious resource. So it is mandatory for our identifier and its eventual metadata schema to be very space efficient to maximize benefit at minimum cost. The basic metadata that will be required to generate and register identifiers must be: minimal in scope clearly specified robust against human error enforced on technical level adequate for public use (no legal or privacy issues) Layers of Digital Media Identification # While we examined existing identifiers we discovered that there is often much confusion about the extent or coverage of what exactly is being identified by a given system. With our idea for a generic cross-media identifier we want to put special weight on being precise with our definitions and found it helpful to distinguish between \u201cdifferent layers of digital media identification\". We found that these layers exist naturally on a scale from abstract to concrete. Our analysis also showed that existing standard identifiers only operate on one or at most two of such layers. The ISCC will be designed as a composite identifier that takes the different layers of media identification into consideration: Layer 1 \u2013 Abstract Creation # In the first and most abstract layer we are concerned with distinguishing between different works or creations in the broadest possible sense . The scope of identification is completely independent of any manifestations of the work, be it physical or digital in nature. It is also agnostic to creators, rights holders or any specific interpretations, expressions or language versions of a work. It only relates to the intangible creation - the idea itself. Layer 2 \u2013 Semantic Field # This layer relates to the meaning or essence of a work. It is an amorphous collection or combination of facts, concepts, categories, subjects, topics, themes, assumptions, observations, conclusions, beliefs and other intangible things that the content conveys. The scope of identification is a set of coordinates within a finite and multidimensional semantic space. Layer 3 \u2013 Generic Manifestation # In this layer we are concerned with the literal structure of a media type specific and normalized manifestation. Namely the basic text, image, audio or video content independent of its semantic meaning or media file encoding and with a tolerance to variation. This \"tolerance to variation\" bundles a set of different versions with corrections, revisions, edits, updates, personalizations, different format encodings or data compressions of the same content under one grouping identifier. A generic manifestation is independent of a final digital media product and is specific to an expression, version or interpretation of a work. Unfortunately it is not obvious where generic manifestation of a work ends and another one starts. It depends on human interpretation and context. How much editing do we allow before we call it a \u201cdifferent\u201d manifestation and give it a different identifier. A practical but only partial solution to this problem is to create a algorithmically defined and testable spectrum of tolerance to variation per media type. This can provide a stable and repeatable process to distinguish between generic content manifestations. But it is important to understand that such a process is not expected to yield results that are always intuitive to human expectations as to where exactly boundaries should be. Layer 4 \u2013 Media Specific Manifestation # This layer relates to a manifestation with a specific encoding . It identifies a data-file encoded and offered in a specific media format including a tolerance to variation to account for minor edits and updates within a format without creating a new identifier. For example one could distinguish between the PDF, DOCX or WEBSITE versions of the same content as generated from a single source publishing system. This layer does only distinguish between products or \"artifacts\" with a given packaging or encoding. Layer 5 \u2013 Exact Representation # In this layer we identify a data-file by its exact binary representation without any interpretation of meaning and without any ambiguity. Even a minimal change in data that might not change the interpretation of content would create a different identifier. Like the first four layers, this layer does also not express any information related to content location or ownership . Layer 6 \u2013 Individual Copy # In the physical world we would call a specific book (one that you can take out of your shelve) an individual copy . This implies a notion of locality and ownership . In the digital world the semantics of an individual copy are very different. An individual copy might be distinguished by a license you own or by a personalized watermark applied by the retailer at time of sale or some digital annotations you have added to your digital media file. While there can only ever be one exact individual copy of a physical object , there always can be endless replicas of an \"individual copy\" of a digital object . It is very important to keep this difference in mind. Ignoring this fact has caused countless misunderstandings and is the source of confusion throughout the media industry \u2013 especially in realm of copyright and license discussions. We could try to define an individual digital copy by its location and exact content on a specific physical storage medium (like a DVD, SSD ...). But this does not account for the fact that it is nearly impossible to stop someone from creating an exact replica of that data or at least a snapshot or recording of the presentation of that data on another storage location. And most importantly such a replica does not affect the original data and even less can make it magically disappear. In contrast, if you give your individual copy of your book to someone else, you won't \"have it\" anymore. It is clear, that with digital media this cannot reliably be the case . The only way would be to build a tamper-proof physical device (secure element) that does not reveal the data itself, which would defeat the purpose by making the content itself unavailable. But there are ways to partially simulate such inherently physical properties in the digital world. Most notably with the emergence of blockchain technology it is now possible to have a cryptographically secured and publicly notarized tamper-proof certificate of ownership. This can serve as a record of agreement about ownership of an \u201cindividual copy\u201d. But is does not by itself enforce location or accessibility of the content, nor does it prove the authorization of the certifying party itself or the legal validity of the agreement. Algorithmic Tools # While many details about the ISCC are still up for discussion we are quite confident about some of the general algorithmic families that will make it into the final specification for the identifier. These will play an important role in how we generate the different components of the identifier: Similarity preserving hash functions (Simhash, Minhash ...) Perceptual hashing (pHash, Blockhash, Chromaprint \u2026) Content defined chunking (Rabin-Karp, FastCDC ...) Merkle trees ISCC Proof-of-Concept # Before we settle on the details of the proposed ISCC identifier, we want to build a simple and reduced proof-of-concept implementation of our ideas. It will enable us and other developers to test with real world data and systems and find out early what works and what doesn't. Update An interactive demo of the concept is available at https://isccdemo.content-blockchain.org/ The minimal viable, first iteration ISCC will be a byte structure built from the following components: Meta-ID # The MetaID will be generated as a similarity preserving hash from minimal generic metadata like title and creators . It operates on Layer 1 and identifies an intangible creation. It is the first and most generic grouping element of the identifier. We will be experimenting with different n-gram sizes and bit-length to find the practical limits of precision and recall for generic metadata. We will also specify a process to disambiguate unintended collisions by adding optional metadata. Partial Content Flag # The Partial Content Flag is a 1-bit flag that indicates if the remaining elements relate to the complete work or only to a subset of it. Media Type Flag # The Media Type Flag is a 3 bit flag that allows us to distinguish between up to 8 generic media types (GMTs) to which our ContentID component applies. We define a generic media type as basic content type such as plain text or raw pixel data that will be specified exactly and extracted from more complex file formats or encodings. We will start with generic text and image types and add audio, video and mixed types later. Content-ID # The ContentID operates on Layer 3 and will be a GMT-specific similarity preserving hash generated from extracted content. It identifies the normalized content of a specific GMT, independent of file format or encoding. It relates to the structural essence of the content and groups similar GMT-specific manifestations of the abstract creation or parts of it (as indicated by the Partial Content Flag). For practical reasons we intentionally skip a Layer 2 component at this time. It would add unnecessary complexity for a basic proof-of-concept implementation. Data-ID # The DataID operates on Layer 4 and will be a similarity preserving hash generated from shift-resistant content-defined chunks from the raw data of the encoded media blob. It groups complete encoded files with similar content and encoding. This component does not distinguish between GMTs as the files may include multiple different generic media types. Instance-ID # The InstanceID operates on Layer 5 and will be the top hash of a merkle tree generated from (potentially content-defined) chunks of raw data of an encoded media blob. It identifies a concrete manifestation and proves the integrity of the full content. We use the merkle tree structure because it also allows as to verify integrity of partial chunks without having to have the full data available. This will be very useful in any scenarios of distributed data storage. We intentionally skip Layer 6 at this stage as content ownership and location will be handled on the blockchain layer of the stack and not by the ISCC identifier itself.","title":"Concept"},{"location":"concept/#iscc-concept","text":"The internet is shifting towards a network of decentralized peer-to-peer transactions. If we want our transactions on the emerging blockchain networks to be about content we need standardized ways to address content. Our transactions might be payments, attributions, reputation, certification, licenses or entirely new kinds of value transfer. All this will happen much faster and easier if we, as a community, can agree on how to identify content in a decentralized environment. This is the first draft of an open proposal to the wider content community for a common content identifier. We would like to share our ideas and spark a conversation with journalists, news agencies, content creators, publishers, distributors, libraries, musicians, scientists, developers, lawyers, rights organizations and all the other participants of the content ecosystem.","title":"ISCC - Concept"},{"location":"concept/#introduction","text":"There are many existing standards for media identifiers serving a wide array of use cases. For example book publishing uses the ISBN , magazines have the ISSN , music industry has ISRC , film has ISAN and science has DOI - each of them serving a set of specific purposes. These identifiers have important roles across many layers. The structure and management of these global identifiers strongly correlates with the grade of achievable automation and potential for innovation within and across different sectors of the media industries. Some communities, like online journalism, don't even have any global persistent identifiers for their content. Many of the established standards manage registration of identifiers in centralized or hierarchical systems involving manual and costly processes. Often the associated metadata is not easily or freely accessible for third parties (if available at all). The overhead, cost and general properties of these systems make them unsuitable for many innovative use cases. Existing and established standards have trouble keeping up with the fast evolving digital economy. For example nowadays major e-book retailers do not even require an ISBN and instead establish their own proprietary identifiers. Amazon has the ASIN , Apple has Apple-ID and Google has GKEY . The fast paced development of the digital media economy has led to an increasing fragmentation of identifiers and new barriers in interoperability. For many tasks current systems need to track and match all the different vendor specific IDs, which is an inefficient and error prone process. Advances in data structures, algorithms, machine learning and the uprise of crypto economics allows us to invent new kinds of media identifiers and re-imagine existing identifiers with innovative use cases in mind. Blockchains and Smart Contracts offer great opportunities in solving many of the challenges of identifier registration, like centralized management, data duplication and disambiguation, vendor lock-in and long term data retention. This is an open proposal to the digital media community and explores the possibilities of a decentralized content identifier system. We\u2019d like to establish an open standard for persistent, unique, vendor independent and content derived cross-media identifiers that are stored and managed in a global and decentralized blockchain. We envision a self-governing ecosystem with a low barrier of entry where commercial and non-commercial initiatives can both innovate and thrive next to each other.","title":"Introduction"},{"location":"concept/#media-identifiers-for-blockchains","text":"Media cataloging systems tend to get out of hand and become complex and often unmanageable. Our design proposal is focused on keeping the ISCC system as simple and more importantly as automatable as possible, while maximizing practical value for the most important use cases \u2014 meaning you should get out more than you have to put in. With this in mind we come to the following basic design decisions:","title":"Media Identifiers for Blockchains"},{"location":"concept/#a-meaningful-identifier","text":"In traditional database systems it is recommended practice to work with surrogate keys as identifiers. A surrogate key has no business meaning and is completely decoupled from the data it identifies. Uniqueness of such identifiers is guaranteed either via centralized incremental assignment by the database system or via random UUIDs which have a very low probability of collisions. While random UUIDs could be generated in a decentralized way, both approaches require some external authority that establishes or certifies the linkage between the identifier and the associated metadata and content. This is why we decided to go with a \u201cmeaningful\u201d content and metadata derived identifier (CMDI) . Anyone will be able to verify that a specific identifier indeed belongs to a given digital content. Even better, anyone can \u201cfind\u201d the identifier for a given content without the need to consult external data sources. This approach also captures essential information about the media in the identifier itself, which is very useful in scenarios of machine learning and data analytics.","title":"A \u201cMeaningful\u201d Identifier"},{"location":"concept/#a-decentralized-identifier","text":"We would like our identifier to be registry agnostic. This means that identifiers can be self-issued in a decentralized and parallel fashion without the need to ask for permission. Even if identifiers are not registered in a central database or on a public blockchain they are still useful in cases where multiple independent parties exchange information about content. The CMDI approach is helpful with common issues like data integrity, validation, de-duplication and disambiguation.","title":"A Decentralized Identifier"},{"location":"concept/#storage-considerations","text":"On a typical public blockchain all data is fully replicated among participants. This allows for independent and autonomous validation of transactions. All blockchain data is highly available, tamper-proof and accessible for free. However, under high load the limited transaction capacity (storage space per unit of time) creates a transaction fee market. This leads to growing transaction costs and makes storage space a scarce and increasingly precious resource. So it is mandatory for our identifier and its eventual metadata schema to be very space efficient to maximize benefit at minimum cost. The basic metadata that will be required to generate and register identifiers must be: minimal in scope clearly specified robust against human error enforced on technical level adequate for public use (no legal or privacy issues)","title":"Storage Considerations"},{"location":"concept/#layers-of-digital-media-identification","text":"While we examined existing identifiers we discovered that there is often much confusion about the extent or coverage of what exactly is being identified by a given system. With our idea for a generic cross-media identifier we want to put special weight on being precise with our definitions and found it helpful to distinguish between \u201cdifferent layers of digital media identification\". We found that these layers exist naturally on a scale from abstract to concrete. Our analysis also showed that existing standard identifiers only operate on one or at most two of such layers. The ISCC will be designed as a composite identifier that takes the different layers of media identification into consideration:","title":"Layers of Digital Media Identification"},{"location":"concept/#layer-1-abstract-creation","text":"In the first and most abstract layer we are concerned with distinguishing between different works or creations in the broadest possible sense . The scope of identification is completely independent of any manifestations of the work, be it physical or digital in nature. It is also agnostic to creators, rights holders or any specific interpretations, expressions or language versions of a work. It only relates to the intangible creation - the idea itself.","title":"Layer 1 \u2013 Abstract Creation"},{"location":"concept/#layer-2-semantic-field","text":"This layer relates to the meaning or essence of a work. It is an amorphous collection or combination of facts, concepts, categories, subjects, topics, themes, assumptions, observations, conclusions, beliefs and other intangible things that the content conveys. The scope of identification is a set of coordinates within a finite and multidimensional semantic space.","title":"Layer 2 \u2013 Semantic Field"},{"location":"concept/#layer-3-generic-manifestation","text":"In this layer we are concerned with the literal structure of a media type specific and normalized manifestation. Namely the basic text, image, audio or video content independent of its semantic meaning or media file encoding and with a tolerance to variation. This \"tolerance to variation\" bundles a set of different versions with corrections, revisions, edits, updates, personalizations, different format encodings or data compressions of the same content under one grouping identifier. A generic manifestation is independent of a final digital media product and is specific to an expression, version or interpretation of a work. Unfortunately it is not obvious where generic manifestation of a work ends and another one starts. It depends on human interpretation and context. How much editing do we allow before we call it a \u201cdifferent\u201d manifestation and give it a different identifier. A practical but only partial solution to this problem is to create a algorithmically defined and testable spectrum of tolerance to variation per media type. This can provide a stable and repeatable process to distinguish between generic content manifestations. But it is important to understand that such a process is not expected to yield results that are always intuitive to human expectations as to where exactly boundaries should be.","title":"Layer 3 \u2013 Generic Manifestation"},{"location":"concept/#layer-4-media-specific-manifestation","text":"This layer relates to a manifestation with a specific encoding . It identifies a data-file encoded and offered in a specific media format including a tolerance to variation to account for minor edits and updates within a format without creating a new identifier. For example one could distinguish between the PDF, DOCX or WEBSITE versions of the same content as generated from a single source publishing system. This layer does only distinguish between products or \"artifacts\" with a given packaging or encoding.","title":"Layer 4 \u2013 Media Specific Manifestation"},{"location":"concept/#layer-5-exact-representation","text":"In this layer we identify a data-file by its exact binary representation without any interpretation of meaning and without any ambiguity. Even a minimal change in data that might not change the interpretation of content would create a different identifier. Like the first four layers, this layer does also not express any information related to content location or ownership .","title":"Layer 5 \u2013 Exact Representation"},{"location":"concept/#layer-6-individual-copy","text":"In the physical world we would call a specific book (one that you can take out of your shelve) an individual copy . This implies a notion of locality and ownership . In the digital world the semantics of an individual copy are very different. An individual copy might be distinguished by a license you own or by a personalized watermark applied by the retailer at time of sale or some digital annotations you have added to your digital media file. While there can only ever be one exact individual copy of a physical object , there always can be endless replicas of an \"individual copy\" of a digital object . It is very important to keep this difference in mind. Ignoring this fact has caused countless misunderstandings and is the source of confusion throughout the media industry \u2013 especially in realm of copyright and license discussions. We could try to define an individual digital copy by its location and exact content on a specific physical storage medium (like a DVD, SSD ...). But this does not account for the fact that it is nearly impossible to stop someone from creating an exact replica of that data or at least a snapshot or recording of the presentation of that data on another storage location. And most importantly such a replica does not affect the original data and even less can make it magically disappear. In contrast, if you give your individual copy of your book to someone else, you won't \"have it\" anymore. It is clear, that with digital media this cannot reliably be the case . The only way would be to build a tamper-proof physical device (secure element) that does not reveal the data itself, which would defeat the purpose by making the content itself unavailable. But there are ways to partially simulate such inherently physical properties in the digital world. Most notably with the emergence of blockchain technology it is now possible to have a cryptographically secured and publicly notarized tamper-proof certificate of ownership. This can serve as a record of agreement about ownership of an \u201cindividual copy\u201d. But is does not by itself enforce location or accessibility of the content, nor does it prove the authorization of the certifying party itself or the legal validity of the agreement.","title":"Layer 6 \u2013 Individual Copy"},{"location":"concept/#algorithmic-tools","text":"While many details about the ISCC are still up for discussion we are quite confident about some of the general algorithmic families that will make it into the final specification for the identifier. These will play an important role in how we generate the different components of the identifier: Similarity preserving hash functions (Simhash, Minhash ...) Perceptual hashing (pHash, Blockhash, Chromaprint \u2026) Content defined chunking (Rabin-Karp, FastCDC ...) Merkle trees","title":"Algorithmic Tools"},{"location":"concept/#iscc-proof-of-concept","text":"Before we settle on the details of the proposed ISCC identifier, we want to build a simple and reduced proof-of-concept implementation of our ideas. It will enable us and other developers to test with real world data and systems and find out early what works and what doesn't. Update An interactive demo of the concept is available at https://isccdemo.content-blockchain.org/ The minimal viable, first iteration ISCC will be a byte structure built from the following components:","title":"ISCC Proof-of-Concept"},{"location":"concept/#meta-id","text":"The MetaID will be generated as a similarity preserving hash from minimal generic metadata like title and creators . It operates on Layer 1 and identifies an intangible creation. It is the first and most generic grouping element of the identifier. We will be experimenting with different n-gram sizes and bit-length to find the practical limits of precision and recall for generic metadata. We will also specify a process to disambiguate unintended collisions by adding optional metadata.","title":"Meta-ID"},{"location":"concept/#partial-content-flag","text":"The Partial Content Flag is a 1-bit flag that indicates if the remaining elements relate to the complete work or only to a subset of it.","title":"Partial Content Flag"},{"location":"concept/#media-type-flag","text":"The Media Type Flag is a 3 bit flag that allows us to distinguish between up to 8 generic media types (GMTs) to which our ContentID component applies. We define a generic media type as basic content type such as plain text or raw pixel data that will be specified exactly and extracted from more complex file formats or encodings. We will start with generic text and image types and add audio, video and mixed types later.","title":"Media Type Flag"},{"location":"concept/#content-id","text":"The ContentID operates on Layer 3 and will be a GMT-specific similarity preserving hash generated from extracted content. It identifies the normalized content of a specific GMT, independent of file format or encoding. It relates to the structural essence of the content and groups similar GMT-specific manifestations of the abstract creation or parts of it (as indicated by the Partial Content Flag). For practical reasons we intentionally skip a Layer 2 component at this time. It would add unnecessary complexity for a basic proof-of-concept implementation.","title":"Content-ID"},{"location":"concept/#data-id","text":"The DataID operates on Layer 4 and will be a similarity preserving hash generated from shift-resistant content-defined chunks from the raw data of the encoded media blob. It groups complete encoded files with similar content and encoding. This component does not distinguish between GMTs as the files may include multiple different generic media types.","title":"Data-ID"},{"location":"concept/#instance-id","text":"The InstanceID operates on Layer 5 and will be the top hash of a merkle tree generated from (potentially content-defined) chunks of raw data of an encoded media blob. It identifies a concrete manifestation and proves the integrity of the full content. We use the merkle tree structure because it also allows as to verify integrity of partial chunks without having to have the full data available. This will be very useful in any scenarios of distributed data storage. We intentionally skip Layer 6 at this stage as content ownership and location will be handled on the blockchain layer of the stack and not by the ISCC identifier itself.","title":"Instance-ID"},{"location":"features/","text":"ISCC - Features # The ISCC (International Standard Content Code) is a modern, generic, and free content identifier. It comes with a number of features built-in: Content Identification # The ISCC is an identifier, that is created from the content file itself. Processing the content according to the ISCC specification creates a unique composite identifier, consisting of four major elements.The ISCC will identify content across multiple, hierarchical layers: From the embedded metadata, the normalized content, the encoded file format up to the individual file. It can be used to automatically distinguish different versions of the same content, to ensure data integrity, to de-duplicate or to disambiguate content in a given content repository. Decentralized Issuance # The ISCC is managed in a decentralized fashion. This means, that anyone with access to the content will be able to create and verify an ISCC based on the content files themselves. The ISCC can be created offline on any local device or app, that supports the suggested standard. The ISCC also ensures that if content files are sent, distributed or otherwise shared among different parties or repositories any participant can be sure to refer to the exact same content file. This will radically simplify digital distribution. Designed for Blockchain # The ISCC is designed to be used in a blockchain environment, but also creates value if being used locally, off-chain or even offline. The ISCC is short enough to be written on any blockchain while preserving its unique features. Or it can be used off-chain within a local content repository for internal processing. Content Versioning # During content creation, review processes or distribution, same or similar files are being exchanged among various parties (editors, distributors, retailers, etc.). With the ISCC registered on the blockchain it is possible to timestamp all content versions and variants in order to create an auditable history of related documents over time. This helps to identify content variations on a time scale in order to make sure that users are referring to the correct same file or related versions of the same content. Related Product Identification # The Content-ID is one component of the ISCC. It is a similarity preserving hash generated from extracted content. It identifies the normalized content of a specific file, independent of file format or encoding. As the Content-ID will remain the same for the same content in various formats, the ISCC automatically connects related products, like PDF-, MS-word or EPUB-files or JPEG- and PNG-files, etc. Granular Content Management # The ISCC can be generated for any work as well as for parts, chunks or individual elements of the content. These elements could be an image, a table, a chapter or a quote within a given document. The relation between parent and child-elements can be preserved in the ISCC identifier. Thus, it is possible to connect the various ID's, obtain their relations and identify the work from which any chunk is taken from. This feature can also help to identify plagiarism, in case chunks from one work have been used in a different work - only with access to the ISCC identifiers. Content Variant Detection # The similarity preserving hash of the Content-ID of the ISCC is able to cluster similar variants of content. It identifies same or similar content and also shows on a scale from 1-64 (or 1-100%) how similar two content variants are. At the same time an application can distinguish between similar but not identical content through the Instance-ID. This can help to identify e.g. watermarked files. Proof of Data Possession # With the ISCC and a standardized signing algorithm it will be possible to verify, whether a user that created the ISCC entry on the blockchain actually had access to the respective content file.","title":"Features"},{"location":"features/#iscc-features","text":"The ISCC (International Standard Content Code) is a modern, generic, and free content identifier. It comes with a number of features built-in:","title":"ISCC - Features"},{"location":"features/#content-identification","text":"The ISCC is an identifier, that is created from the content file itself. Processing the content according to the ISCC specification creates a unique composite identifier, consisting of four major elements.The ISCC will identify content across multiple, hierarchical layers: From the embedded metadata, the normalized content, the encoded file format up to the individual file. It can be used to automatically distinguish different versions of the same content, to ensure data integrity, to de-duplicate or to disambiguate content in a given content repository.","title":"Content Identification"},{"location":"features/#decentralized-issuance","text":"The ISCC is managed in a decentralized fashion. This means, that anyone with access to the content will be able to create and verify an ISCC based on the content files themselves. The ISCC can be created offline on any local device or app, that supports the suggested standard. The ISCC also ensures that if content files are sent, distributed or otherwise shared among different parties or repositories any participant can be sure to refer to the exact same content file. This will radically simplify digital distribution.","title":"Decentralized Issuance"},{"location":"features/#designed-for-blockchain","text":"The ISCC is designed to be used in a blockchain environment, but also creates value if being used locally, off-chain or even offline. The ISCC is short enough to be written on any blockchain while preserving its unique features. Or it can be used off-chain within a local content repository for internal processing.","title":"Designed for Blockchain"},{"location":"features/#content-versioning","text":"During content creation, review processes or distribution, same or similar files are being exchanged among various parties (editors, distributors, retailers, etc.). With the ISCC registered on the blockchain it is possible to timestamp all content versions and variants in order to create an auditable history of related documents over time. This helps to identify content variations on a time scale in order to make sure that users are referring to the correct same file or related versions of the same content.","title":"Content Versioning"},{"location":"features/#related-product-identification","text":"The Content-ID is one component of the ISCC. It is a similarity preserving hash generated from extracted content. It identifies the normalized content of a specific file, independent of file format or encoding. As the Content-ID will remain the same for the same content in various formats, the ISCC automatically connects related products, like PDF-, MS-word or EPUB-files or JPEG- and PNG-files, etc.","title":"Related Product Identification"},{"location":"features/#granular-content-management","text":"The ISCC can be generated for any work as well as for parts, chunks or individual elements of the content. These elements could be an image, a table, a chapter or a quote within a given document. The relation between parent and child-elements can be preserved in the ISCC identifier. Thus, it is possible to connect the various ID's, obtain their relations and identify the work from which any chunk is taken from. This feature can also help to identify plagiarism, in case chunks from one work have been used in a different work - only with access to the ISCC identifiers.","title":"Granular Content Management"},{"location":"features/#content-variant-detection","text":"The similarity preserving hash of the Content-ID of the ISCC is able to cluster similar variants of content. It identifies same or similar content and also shows on a scale from 1-64 (or 1-100%) how similar two content variants are. At the same time an application can distinguish between similar but not identical content through the Instance-ID. This can help to identify e.g. watermarked files.","title":"Content Variant Detection"},{"location":"features/#proof-of-data-possession","text":"With the ISCC and a standardized signing algorithm it will be possible to verify, whether a user that created the ISCC entry on the blockchain actually had access to the respective content file.","title":"Proof of Data Possession"},{"location":"implementations/","text":"ISCC - Implementations # Developer Libraries # Language Author(s) URL Python3 Patricia Schinke, Titusz Pan https://pypi.python.org/pypi/iscc Go (golang) Patricia Schinke, Marvin Schmies https://github.com/coblo/iscc-golang If you are missing an implementation in your favorite programming language, please feel free to port it over. The reference implementation is a single python module and we have language independent test data in JSON . Demo Implementations # Blockchain wallet demo: https://github.com/coblo/gui-demo Smart License demo: https://github.com/coblo/smartlicense Early concept demo: https://isccdemo.content-blockchain.org/","title":"Implementations"},{"location":"implementations/#iscc-implementations","text":"","title":"ISCC - Implementations"},{"location":"implementations/#developer-libraries","text":"Language Author(s) URL Python3 Patricia Schinke, Titusz Pan https://pypi.python.org/pypi/iscc Go (golang) Patricia Schinke, Marvin Schmies https://github.com/coblo/iscc-golang If you are missing an implementation in your favorite programming language, please feel free to port it over. The reference implementation is a single python module and we have language independent test data in JSON .","title":"Developer Libraries"},{"location":"implementations/#demo-implementations","text":"Blockchain wallet demo: https://github.com/coblo/gui-demo Smart License demo: https://github.com/coblo/smartlicense Early concept demo: https://isccdemo.content-blockchain.org/","title":"Demo Implementations"},{"location":"license/","text":"License # TITLE : ISCC - Content Identifiers ISCC : CCDFPFc87MhdT-CTh49Go1xZxte-CDLY37krCTvv6 CC BY-NC-SA 4.0 License Copyright \u00a9 2016 - 2018 Content Blockchain Project This work is licensed under a Creative Commons (CC BY-NC-SA 4.0) .","title":"License"},{"location":"license/#license","text":"TITLE : ISCC - Content Identifiers ISCC : CCDFPFc87MhdT-CTh49Go1xZxte-CDLY37krCTvv6 CC BY-NC-SA 4.0 License Copyright \u00a9 2016 - 2018 Content Blockchain Project This work is licensed under a Creative Commons (CC BY-NC-SA 4.0) .","title":"License"},{"location":"specification/","text":"ISCC - Specification v1.0.0 # Abstract # The International Standard Content Code ( ISCC ) , is an open and decentralized digital media identifier. An ISCC can be created from digital content and its basic metadata by anybody who follows the procedures of the ISCC specification or by using open source software that supports ISCC creation conforming to the ISCC specification . Note to Readers # For public discussion of issues for this specification please use the Github issue tracker: https://github.com/coblo/iscc-specs/issues . The latest published version of this specification can be found at http://iscc.codes/specification/ . Public review, discussion and contributions are welcome. About this Document # This document proposes an open and vendor neutral ISCC standard and describes the technical procedures to create and manage ISCC identifiers. The first version of this document is produced as a prototype by the Content Blockchain Project and received funding from the Google Digital News Initiative (DNI) . The content of this document is determined by its authors in an open and public consensus process. Conventions and Terminology # The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in [RFC 2119] . Definitions # Basic Metadata: Minimal set of metadata about the content that is identified by an ISCC . This metadata may impact the derived Meta-ID Component Character: Throughout this specification a character is meant to be interpreted as one Unicode code point. This also means that due to the structure of Unicode a character is not necessarily a full glyph but might be a combining accent or similar. Digital Media Object: A blob of raw bytes with some media type specific encoding. Extended Metadata: Metadata that is not encoded within the ISCC Meta-ID but may be supplied together with the ISCC . Generic Media Type: A basic content type such as plain text in a normalized and generic ( UTF-8 ) encoding format. ISCC : International Standard Content Code ISCC Code : The printable text encoded representation of an ISCC ISCC Digest : The raw binary data of an ISCC Introduction # An ISCC permanently identifies content at multiple levels of granularity . It is algorithmically generated from basic metadata and the contents of a digital media object. It is designed for being registered and stored on a public and decentralized blockchain. An ISCC for a media object can be created and registered by the content author, a publisher, a service provider or anybody else. By itself the ISCC and its basic registration on a blockchain does not make any statement or claim about authorship or ownership of the identified content. ISCC Structure # A Fully Qualified ISCC Digest is a fixed size sequence of 36 bytes (288 bits) assembled from multiple sub-components. The Fully Qualified ISCC Code is a 52 character encoded printable string representation of a complete ISCC Digest . This is a high-level overview of the ISCC creation process: ISCC Components # The ISCC Digest is built from multiple self-describing 72-bit components: Components: Meta-ID Content-ID Data-ID Instance-ID Context: Intangible creation Content similarity Data similarity Data checksum Input: Metadata Extracted content Raw data Raw data Algorithms: Similarity Hash Type specific CDC , Minimum Hash CDC , Hash Tree Size: 72 bits 72 bits 72 bits 72 bits ISCC components MAY be used separately or in combination by applications for various purposes. Individual components MUST be presented as 13- character base58-iscc encoded strings to end users and MAY be prefixed with their component name. Single component ISCC -Code (13 characters) Meta-ID : CCDFPFc87MhdT Combinations of components MUST include the Meta-ID component and MUST be ordered as Meta-ID , Content-ID , Data-ID , and Instance-ID . Individual components MAY be skipped and SHOULD be separated with hyphens. A combination of components SHOULD be prefixed with \" ISCC \". Combination of ISCC -Code components ISCC : CCPktvj3dVoVa-CTPCWTpGPMaLZ-CDL6QsUZdZzog A Fully Qualified ISCC Code is an ordered sequence of Meta-ID, Content-ID, Data-ID, and Instance-ID codes. It SHOULD be prefixed with ISCC and MAY be separated by hyphens. Fully Qualified ISCC -Code (52 characters) ISCC : CCDFPFc87MhdTCTWAGYJ9HZGj1CDhydSjutScgECR4GZ8SW5a7uc Fully Qualified ISCC -Code with hyphens (55 characters) ISCC : CCDFPFc87MhdT-CTWAGYJ9HZGj1-CDhydSjutScgE-CR4GZ8SW5a7uc Component Types # Each component has the same basic structure of a 1-byte header and a 8-byte body section. The 1-byte header of each component is subdivided into 2 nibbles (4 bits). The first nibble specifies the component type while the second nibble is component specific. The header only needs to be carried in the encoded representation. As similarity searches across different components are of little use, the type information contained in the header of each component can be safely ignored after an ISCC has been decomposed and internally typed by an application. List of Component Headers # Component Nibble-1 Nibble-2 Byte Code Meta-ID 0000 0000 - ISCC version 1 0x00 CC Content-ID-Text 0001 0000 - Content Type Text 0x10 CT Content-ID-Text PCF 0001 0001 - Content Type Text + PCF 0x11 Ct Content-ID-Image 0001 0010 - Content Type Image 0x12 CY Content-ID-Image PCF 0001 0011 - Content Type Image + PCF 0x13 Ci Content-ID-Audio 0001 0100 - Content Type Audio 0x14 CA Content-ID-Audio PCF 0001 0101 - Content Type Audio + PCF 0x15 Ca Content-ID-Video 0001 0110 - Content Type Video 0x16 CV Content-ID-Video PCF 0001 0111 - Content Type Video + PCF 0x17 Cv Content-ID-Mixed 0001 1000 - Content Type Mixed 0x18 CM Content-ID Mixed PCF 0001 1001 - Content Type Mixed + PCF 0x19 Cm Data-ID 0010 0000 - Reserved 0x20 CD Instance-ID 0011 0000 - Reserved 0x30 CR The body section of each component is specific to the component and always 8-bytes and can thus be fit into a 64-bit integer for efficient data processing. The following sections give an overview of how the different components work and how they are generated. Meta-ID Component # The Meta-ID component starts with a 1-byte header 00000000 . The first nibble 0000 indicates that this is a Meta-ID component type. The second nibble 0000 indicates that it belongs to an ISCC of version 1. All subsequent components are expected to follow the specification of a version 1 ISCC . The Meta-ID body is built from a 64-bit similarity_hash over 4- character n-grams of the basic metadata of the content to be identified. The basic metadata supplied to the META-ID generating function is assumed to be UTF-8 encoded. Errors that occur during the decoding of such a bytestring input to a native Unicode MUST terminate the process and must not be silenced. An ISCC generating application MUST provide a meta_id function that accepts minimal and generic metadata and returns a Base58- ISCC encoded Meta-ID component and trimmed metadata. Inputs to Meta-ID function # Name Type Required Description title text Yes The title of an intangible creation. extra text No An optional short statement that distinguishes this intangible creation from another one for the purpose of Meta-ID uniqueness. (default: empty string) version integer No ISCC version number. (default: 0) Note The basic metadata inputs are intentionally simple and generic. We abstain from more specific metadata for Meta-ID generation in favor of compatibility across industries. Imagine a creators input-field for metadata. Who would you list as the creators of a movie? The directors, writers the main actors? Would you list some of them or if not how do you decide whom you will list. All disambiguation of similar title data can be accomplished with the extra-field. Industry- and application-specific metadata requirements can be supplied as extended metadata with ISCC registration. Generate Meta-ID # An ISCC generating application must follow these steps in the given order to produce a stable Meta-ID: Verify the requested ISCC version is supported by your implementation. Apply text_pre_normalize separately to the title and extra inputs. Apply text_trim to the results of step 1. The results of this step MUST be supplied as basic metadata for ISCC registration. Concatenate trimmed title and extra from using a space ( \\u0020 ) as a seperator. Apply text_normalize to the results of step 3. Create a list of 4 character n-grams by sliding character -wise through the result of step 4. Encode each n-gram from step 5 to an UTF-8 bytestring and calculate its xxHash64 digest. Apply similarity_hash to the list of digests from step 6. Prepend the 1-byte component header according to component type and ISCC version (e.g. 0x00 ) to the results of step 7. Encode the resulting 9 byte sequence with encode Return encoded Meta-ID, trimmed title and trimmed extra data. See also: Meta-ID reference code Text trimming When trimming text be sure to trim the byte-length of the UTF-8 encoded version and not the number of characters. The trim point MUST be such, that it does not cut into multibyte characters. Characters might have different UTF-8 byte-length. For example \u00fc is 2-bytes, \u9a69 is 3-bytes and \ud841\udf0e is 4-bytes. So the trimmed version of a string with 128 \u9a69 -characters will result in a 42- character string with a 126-byte UTF-8 encoded length. This is necessary because the results of this operation will be stored as basic metadata with strict byte size limits on the blockchain. Automated Data-Ingestion Applications that perform automated data-ingestion SHOULD apply a customized preliminary normalization to title data tailored to the dataset. Depending on catalog data removing pairs of brackets [], (), {}, and text in between them or cutting all text after the first occurence of a semicolon (;) or colon (:) can vastly improve deduplication. Dealing with Meta-ID collisions # Ideally we want multiple ISCCs that identify different manifestations of the same intangible creation to be automatically grouped by an identical leading Meta-ID component. We call such a natural grouping an intended component collision . Metadata, captured and edited by humans, is notoriously unreliable. By using normalization and a similarity hash on the metadata we account for some of this variation while keeping the Meta-ID component somewhat stable. Auto-generated Meta-IDs components are expected to miss some intended collisions. An application SHOULD check for such missed intended component collisions before registering a new Meta-ID with the canonical registry of ISCCs by conducting a similarity search and asking for user feedback. But what about unintended component collisions ? Such collisions might happen because two different intangible creations have very similar or even identical metadata. But they might also happen simply by chance. With 2^56 possibile Meta-ID components the probability of random collisions rises in an S-curved shape with the number of deployed ISCCs (see: Hash Collision Probabilities ). We should keep in mind that, the Meta-ID component is only one part of a fully qualified ISCC Code . Unintended collisions of the Meta-ID component are generally deemed as acceptable and expected . If for any reason an application wants to avoid unintended collisions with pre-existing Meta-ID components it may utilize the extra -field. An application MUST first generate a Meta-ID without asking the user for input to the extra -field and then first check for collisions with the canonical registry of ISCCs. After it finds a collision with a pre-existing Meta-ID it may display the metadata of the colliding entry and interact with the user to determine if it indeed is an unintended collision. Only if the user indicates an unintended collision, may the application ask for a disambiguation that is then added as an amendment to the metadata via the extra -field to create a different Meta-ID component. The application may repeat the pre-existence check until it finds no collision or a user intended collision. The application MUST NOT supply auto-generated input to the extra -field. It is our opinion that the concept of intended collisions of Meta-ID components is generally useful concept and a net positive. But one must be aware that this characteristic also has its pitfalls. It is by no means an attempt to provide an unambiguous - agreed upon - definition of \"identical intangible creations\" . Content-ID Component # The Content-ID component has multiple subtypes. The subtypes correspond with the Generic Media Types ( GMT ) . A fully qualified ISCC can only have one Content-ID component of one specific GMT , but there may be multiple ISCCs with different Content-ID types per digital media object. A Content-ID is generated in two broad steps. In the first step, we extract and convert content from a rich media type to a normalized GMT . In the second step, we use a GMT -specific process to generate the Content-ID component of an ISCC . Generic Media Types # The Content-ID type is signaled by the first 3 bits of the second nibble of the first byte of the Content-ID: Conent-ID Type Nibble 2 Bits 0-3 Description text 000 Generated from extracted and normalized plain-text image 001 Generated from normalized grayscale pixel data audio 010 To be defined in later version of specification video 011 To be defined in later version of specification mixed 100 Generated from multiple Content-IDs 101, 110, 111 Reserved for future versions of specification Content-ID-Text # The Content-ID-Text is built from the extracted plain-text content of an encoded media object. To build a stable Content-ID-Text the plain-text content must first be extracted from the digital media object. It should be extracted in a way that is reproducible. There are many different text document formats out in the wilde and extracting plain-text from all of them is anything but a trivial task. While text-extraction is out of scope for this specification it is RECOMMENDED, that plain-text content SHOULD be extracted with the open-source Apache Tika v1.17 toolkit, if a generic reproducibility of the Content-ID-Text component is desired. An ISCC generating application MUST provide a content_id(text, partial=False) function that accepts UTF-8 encoded plain text and a boolean indicating the partial content flag as input and returns a Content-ID with GMT type text . The procedure to create a Content-ID-Text is as follows: Apply text_pre_normalize . Apply text_normalize to the text input. Split the normalized text into a list of words at whitespace boundaries. Create a list of 5 word shingles by sliding word-wise through the list of words. Create a list of 32-bit unsigned integer features by applying xxHash32 to results of step 4. Apply minimum_hash to the list of features from step 5. Collect the least significant bits from the 128 MinHash features from step 6. Create two 64-bit digests from the first and second half of the collected bits. Apply similarity_hash to the digests returned from step 8. Prepend the 1-byte component header ( 0x10 full content or 0x11 partial content). Encode and return the resulting 9-byte sequence with encode . See also: Content-ID-Text reference code Content-ID-Image # For the Content-ID-Image we are opting for a DCT-based perceptual image hash instead of a more sophisticated keypoint detection based method. In view of the generic deployability of the ISCC we chose an algorithm that has moderate computation requirements and is easy to implement while still being robust against common image manipulations. An ISCC generating application MUST provide a content_id_image(image, partial=False) function that accepts a local file path to an image and returns a Content-ID with GMT type image . The procedure to create a Content-ID-Image is as follows: Apply image_normalize to receive a two-dimensional array of grayscale pixel data. Apply image_hash to the results of step 1. Prepend the 1-byte component header ( 0x12 full content or 0x13 partial content) to results of step 2. Encode and return the resulting 9-byte sequence with encode See also: Content-ID-Image reference code Image Data Input The content_id_image function may optionally accept the raw byte data of an encoded image or an internal native image object as input for convenience. JPEG Decoding Decoding of JPEG images is non-deterministic. Different image processing libraries may yield diverging pixel data and result in different Image-IDs. The reference implementation currently uses the builtin decoder of the Python Pillow imaging library. Future versions of the ISCC specification may define a custom deterministic JPEG decoding procedure. Content-ID-Mixed # The Content-ID-Mixed aggregates multiple Content-IDs of the same or different types. It may be used for digital media objects that embed multiples types of media or for collections of contents of the same type. First we have to collect contents from the mixed media object or content collection and generate Content-IDs for each item. An ISCC conforming application must provide a content_id_mixed function that takes a list of Content-ID Codes as input and returns a Content-ID-Mixed. Follow these steps to create a Content-ID-Mixed: Signature: conent_id_mixed(cids: List[str], partial: bool=False) -> str Decode the list of Content-IDs. Extract the first 8-bytes from each digest ( Note : this includes the header part of the Content-IDs). Apply similarity_hash to the list of digests from step 2. Prepend the 1-byte component header( 0x18 full content or 0x19 partial content) Apply encode to the result of step 5 and return the result. See also: Content-ID-Mixed reference code Partial Content Flag ( PCF ) # The last bit of the header byte of the Content-ID is the \"Partial Content Flag\". It designates if the Content-ID applies to the full content or just some part of it. The PCF MUST be set as a 0 -bit ( full GMT -specific content ) by default. Setting the PCF to 1 enables applications to create multiple linked ISCCs of partial extracts of a content collection. The exact semantics of partial content are outside of the scope of this specification. Applications that plan to support partial Content-IDs MUST clearly define their semantics. PCF Linking Example Let's assume we have a single newspaper issue \"The Times - 03 Jan 2009\". You would generate one Meta-ID component with title \"The Times\" and extra \"03 Jan 2009\". The resulting Meta-ID component will be the grouping prefix in this szenario. We use a Content-ID-Mixed with PCF 0 (not partial) for the ISCC of the newspaper issue. We generate Data-ID and Instance-ID from the print PDF of the newspaper issue. To create an ISCC for a single extracted image that should convey context with the newspaper issue we reuse the Meta-ID of the newspaper issue and create a Content-ID-Image with PCF 1 (partial to the newspaper issue). For the Data-ID or Instance-ID of the image we are free to choose if we reuse those of the newspaper issue or create separate ones. The former would express strong specialization of the image to the newspaper issue (not likely to be useful out of context). The latter would create a stronger link to an eventual standalone ISCC of the image. Note that in any case the ISCC of the individual image retains links in both ways: Image is linked to the newspaper issue by identical Meta-ID component Image is linked to the standalone version of the image by identical Content-ID-Image body This is just one example that illustrates the flexibility that the PCF -Flag provides in concert with a grouping Meta-ID. With great flexibility comes great danger of complexity. Applications SHOULD do careful planning before using the PCF -Flag with internally defined semantics. Data-ID Component # For the Data-ID that encodes data similarity we use a content defined chunking algorithm that provides some shift resistance and calculate the MinHash from those chunks. To accomodate for small files the first 100 chunks have a ~140-byte size target while the remaining chunks target ~ 6kb in size. The Data-ID is built from the raw encoded data of the content to be identified. An ISCC generating application MUST provide a data_id function that accepts the raw encoded data as input. Generate Data-ID # Apply data_chunks to the raw encoded content data. For each chunk calculate the xxHash32 integer hash. Apply minimum_hash to the resulting list of 32-bit unsigned integers. Collect the least significant bits from the 128 MinHash features. Create two 64-bit digests from the first and second half of the collected bits. Apply similarity_hash to the results of step 5. Prepend the 1-byte component header (e.g. 0x20). Apply encode to the result of step 5 and return the result. See also: Data-ID reference code Instance-ID Component # The Instance-ID is built from the raw data of the media object to be identified and serves as checksum for the media object. The raw data of the media object is split into 64-kB data-chunks. Then we build a hash-tree from those chunks and use the truncated tophash (merkle root) as component body of the Instance-ID. To guard against length-extension attacks and second pre-image attacks we use double sha256 for hashing. We also prefix the hash input data with a 0x00 -byte for the leaf nodes hashes and with a 0x01 -byte for the internal node hashes. While the Instance-ID itself is a non-cryptographic checksum, the full tophash may be supplied in the extended metadata of an ISCC secure integrity verification is required. An ISCC generating application MUST provide a instance_id function that accepts the raw data file as input and returns an encoded Instance-ID and a full hex-encoded 256-bit tophash . Generate Instance-ID # Split the raw bytes of the encoded media object into 64-kB chunks. For each chunk calculate the sha256d of the concatenation of a 0x00 -byte and the chunk bytes. We call the resulting values leaf node hashes ( LNH ). Calculate the next level of the hash tree by applying sha256d to the concatenation of a 0x01 -byte and adjacent pairs of LNH values. If the length of the list of LNH values is uneven concatenate the last LNH value with itself. We call the resulting values internal node hashes ( INH ). Recursively apply 0x01 -prefixed pairwise hashing to the results of step 3 until the process yields only one hash value. We call this value the tophash . Trim the resulting tophash to the first 8 bytes. Prepend the 1-byte component header (e.g. 0x30 ). Encode resulting 9-byte sequence with encode to an Instance-ID Code Hex-Encode the tophash Return the Intance-ID and the hex-encoded tophash See also: Instance-ID reference code Applications may carry, store, and process the leaf node hashes for advanced streaming data identification or partial data integrity verification. ISCC Metadata # As a generic content identifier the ISCC makes minimal assumptions about metadata that must or should be supplied together with an ISCC . The RECOMMENDED data-interchange format for ISCC metadata is JSON . We distinguish between Basic Metadata and Extended Metadata : Basic Metadata # Basic metadata for an ISCC is metadata that is explicitly defined by this specification. The following table enumerates basic metadata fields for use in the top-level of the JSON metadata object: Name Type Required Description version integer No Version of ISCC Specification. Assumed to be 1 if omitted. title text Yes The title of an intangible creation identified by the ISCC . The normalized and trimmed UTF-8 encoded text MUST not exceed 128 Bytes. The result of processing title and extra data with the meta_id function MUST match the Meta-ID component of the ISCC . extra text No An optional short statement that distinguishes this intangible creation from another one for the purpose of Meta-ID uniqueness. tophash text (hex) No The full hex-encoded tophash (merkle root) returned by the instance_id function. meta array No A list of one or more extended metadata entries. Must include at least one entry if specified. Attention Depending on adoption and real world use, future versions of this specification may define new basic metadata fields. Applications MAY add custom fields at the top level of the JSON object but MUST prefix those fields with an underscore to avoid collisions with future extensions of this specification. Extended Metadata # Extended metadata for an ISCC is metadata that is not explicitly defined by this specification. All such metadata SHOULD be supplied as JSON objects within the top-level meta array field. This allows for a flexible and extendable way to supply additional industry specific metadata about the identified content. Extended metadata entries MUST be wrapped in JSON object of the following structure: Name Description schema The schema -field may indicate a well known metadata schema (such as Dublin Core, IPTC, ID3v2, ONIX) that is used. RECOMMENDED schema : \" schema.org \" mediatype The mediatype -field specifies an IANA Media Type . RECOMMENDED mediatype : \"application/ld+json\" url An URL that is expected to host the metadata with the indicated schema and mediatype . This field is only required if the data -field is omitted. data The data -field holds the metadata conforming to the indicated schema and mediatype. It is only required if the url field is omitted. ISCC Registration # The ISCC is a decentralized identifier. ISCCs can be generated for content by anybody who has access to the content. Due to the clustering properties of its components the ISCC provides utility in data interchange and de-duplication scenarios even without a global registry. There is no central authority for the registration of ISCC identifiers or certification of content authorship. As an open system the ISCC allows any person or organization to offer ISCC registration services as they see fit and without the need to ask anyone for permission. This also presumes that no person or organization may claim exclusive authority about ISCC registration. Blockchain Registry # A well known, decentralized, open, and public registry for canonical discoverability of ISCC identified content is of great value. For this reason it is RECOMMENDED to register ISCC identifiers on the open iscc data-stream of the Content Blockchain . For details please refer to the ISCC -Stream specification of the Content Blockchain. ISCC Embedding # Embedding ISCC codes into content is only RECOMMENDED if it does not create a side effect. We call it a side effect if embedding an ISCC code modifies the content to such an extent, that it yields a different ISCC code. Side effects will depend on the combination of ISCC components that are to be embedded. A Meta-ID can always be embedded without side effect because it does not depend on the content itself. Content-ID and Data-ID may not change if embedded in larger media objects. Instance-IDs cannot easily be embedded as they will inevitably have a side effect on the post-embedding Instance-ID without special processing. Applications MAY embed ISCC codes that have side effects if they specify a procedure by which the embedded ISCC codes can be stripped in such a way that the stripped content will yield the original embedded ISCC codes. ISCC Embedding We are able to embed the following combination of components from the markdown version of this document into the document itself because adding or removing them has no side effect: ISCC : CCDbMYw6NfC8a-CTfLV4GoxGh7f-CDLmtRpZGVJhU ISCC URI Scheme # The purpose of the ISCC URI scheme based on RFC 3986 is to enable users to easily discover information like metadata or license offerings about a ISCC marked content by simply clicking a link on a webpage or by scanning a QR-Code. The scheme name is iscc . The path component MUST be a fully qualified ISCC Code without hyphens. An optional stream query key MAY indicate the blockchain stream information source. If the stream query key is omitted applications SHOULD return information from the open ISCC Stream . The scheme name component (\"iscc:\") is case-insensitive. Applications MUST accept any combination of uppercase and lowercase letters in the scheme name. All other URI components are case-sensitive. Applications MAY register themselves as handler for the \"iscc:\" URI scheme if no other handler is already registered. If another handler is already registered an application MAY ask the user to change it on the first run of the application. URI Syntax # <foo> means placeholder, [bar] means optional. iscc:<fq-iscc-code>[?stream=<name>] URI Example # iscc:11TcMGvUSzqoM1CqVA3ykFawyh1R1sH4Bz8A1of1d2Ju4VjWt26S?stream=smart-license Procedures & Algorithms # Base58- ISCC # The ISCC uses a custom per-component data encoding similar to the zbase62 encoding by Zooko Wilcox-O'Hearn but with a 58- character symbol table. The encoding does not require padding and will always yield component codes of 13 characters length for ths 72-bit component digests. The predictable size of the encoding is a property that allows for easy composition and decomposition of components without having to rely on a delimiter (hyphen) in the ISCC code representation. Colliding body segments of the digest are preserved by encoding the header and body separately. The ASCII symbol table also minimizes transcription and OCR errors by omitting the easily confused characters 'O', '0', 'I', 'l' and is shuffled to generate human readable component headers. Symbol table SYMBOLS = \"C23456789rB1ZEFGTtYiAaVvMmHUPWXKDNbcdefghLjkSnopRqsJuQwxyz\" encode # Signature: encode(digest: bytes) -> str The encode function accepts a 9-byte ISCC Component Digest and returns the Base58- ISCC encoded alphanumeric string of 13 characters which we call the ISCC -Component Code . See also: Base- ISCC Encoding reference code decode # Signature: decode(code: str) -> bytes the decode function accepts a 13- character ISCC -Component Code and returns the corresponding 9-byte ISCC -Component Digest . See also: Base- ISCC Decoding reference code Content Normalization # The ISCC standardizes some content normalization procedures to support reproducible and stable identifiers. Following the list of normalization functions that MUST be provided by a conforming implementation. text_pre_normalize # Signature: text_pre_normalize(text: str|bytes) -> str Decodes raw plain-text data and applies Unicode Normalization Form KC (NFKC) . The plain-text data MUST be stripped of any markup beforehand. Text input is expected to be UTF-8 encoded plain-text data or a native type of the implementing programming language that supports Unicode. Text decoding errors MUST fail with an error. See also: Text pre-normalization reference code text_trim # Signature: text_trim(text: str) -> str Trim text such that its UTF-8 encoded byte representation does not exceed 128-bytes each. See also: Text trimming reference code text_normalize # Signature: text_normalize(text: str) -> str We define a text normalization function that is specific to our application. It takes unicode text as an input and returns normalized Unicode text for further algorithmic processing. The text_normalize function performs the following operations in the given order while each step works with the results of the previous operation: Decompose the input text by applying Unicode Normalization Form D (NFD) . Filter and normalize text by iterating over unicode characters while: replacing groups of one or more consecutive Separator characters ( Unicode categories Zs, Zl and Zp) with exactly one Unicode SPACE character ( U+0020 ) . removing characters that are not in one of the Unicode categories Separator , Letter , Number or Symbol . converting characters to lowercase. Remove any leading or trailing Separator characters. Re-Compose the text by applying Unicode Normalization Form C (NFC) . See also: Text normalization reference code image_normalize # Signature: image_normalize(img) -> List[List[int]] Accepts a file path, byte-stream or raw binary image data and MUST at least support JPEG, PNG, and GIF image formats. Normalize the image with the following steps: Convert the image to grayscale Resize the image to 32x32 pixels using bicubic interpolation Create a 32x32 two-dimensional array of 8-bit grayscale values from the image data See also: Image normalization reference code Feature Hashing # The ISCC standardizes various feature hashing algorithms that reduce content features to a binary vector used as the body of the various Content-ID components. similarity_hash # Signature: similarity_hash(hash_digests: Sequence[ByteString]) -> bytes The similarity_hash function takes a sequence of hash digests which represent a set of features. Each of the digests MUST be of equal size. The function returns a new hash digest (raw 8-bit bytes) of the same size. For each bit in the input hashes calculate the number of hashes with that bit set and subtract the the count of hashes where it is not set. For the output hash set the same bit position to 0 if the count is negative or 1 if it is zero or positive. The resulting hash digest will retain similarity for similar sets of input hashes. See also [Charikar2002] . See also: Similarity hash reference code minimum_hash # Signature: minimum_hash(features: Iterable[int]) -> List[int] The minimum_hash function takes an arbitrary sized set of 32-bit integer features and reduces it to a fixed size vector of 128 features such that it preserves similarity with other sets. It is based on the MinHash implementation of the datasketch library by Eric Zhu . See also: Minimum hash reference code image_hash # Signature: image_hash(pixels: List[List[int]]) -> bytes Perform a discrete cosine transform per row of input pixels. Perform a discrete cosine transform per column on the resulting matrix from step 2. Extract upper left 8x8 corner of array from step 2 as a flat list. Calculate the median of the results from step 3. Create a 64-bit digest by iterating over the values of step 5 and setting a 1 - for values above median and 0 for values below or equal to median. Return results from step 5. See also: Image hash reference code Content Defined Chunking # For shift resistant data chunking the ISCC requires a custom chunking algorithm: data_chunks # Signature: data_chunks(data: stream) -> Iterator[bytes] The data_chunks function accepts a byte-stream and returns variable sized chunks. Chunk boundaries are determined by a gear based chunking algorithm based on [WenXia2016] . See also: CDC reference code Conformance Testing # An application that claims ISCC conformance MUST pass the ISCC conformance test suite. The test suite is available as json data in our Github Repository . Test Data is structured as follows: { \"<function_name>\" : { \"<test_name>\" : { \"inputs\" : [ \"<value1>\" , \"<value2>\" ], \"outputs\" : [ \"value1>\" , \"<value2>\" ] } } } Outputs that are expected to be raw bytes are embedded as HEX encoded strings in JSON and prefixed with hex: to support automated decoding during implementation testing. Example Byte outputs in JSON testdata: { \"data_chunks\": { \"test_001_cat_jpg\": { \"inputs\": [\"cat.jpg\"], \"outputs\": [\"hex:ffd8ffe1001845786966000049492a0008\", ...] } } } License # Copyright \u00a9 2016 - 2018 Content Blockchain Project This work is licensed under a Creative Commons (CC BY-NC-SA 4.0) .","title":"Specification"},{"location":"specification/#iscc-specification-v100","text":"","title":"ISCC - Specification v1.0.0"},{"location":"specification/#abstract","text":"The International Standard Content Code ( ISCC ) , is an open and decentralized digital media identifier. An ISCC can be created from digital content and its basic metadata by anybody who follows the procedures of the ISCC specification or by using open source software that supports ISCC creation conforming to the ISCC specification .","title":"Abstract"},{"location":"specification/#note-to-readers","text":"For public discussion of issues for this specification please use the Github issue tracker: https://github.com/coblo/iscc-specs/issues . The latest published version of this specification can be found at http://iscc.codes/specification/ . Public review, discussion and contributions are welcome.","title":"Note to Readers"},{"location":"specification/#about-this-document","text":"This document proposes an open and vendor neutral ISCC standard and describes the technical procedures to create and manage ISCC identifiers. The first version of this document is produced as a prototype by the Content Blockchain Project and received funding from the Google Digital News Initiative (DNI) . The content of this document is determined by its authors in an open and public consensus process.","title":"About this Document"},{"location":"specification/#conventions-and-terminology","text":"The key words \"MUST\", \"MUST NOT\", \"REQUIRED\", \"SHALL\", \"SHALL NOT\", \"SHOULD\", \"SHOULD NOT\", \"RECOMMENDED\", \"MAY\", and \"OPTIONAL\" in this document are to be interpreted as described in [RFC 2119] .","title":"Conventions and Terminology"},{"location":"specification/#definitions","text":"Basic Metadata: Minimal set of metadata about the content that is identified by an ISCC . This metadata may impact the derived Meta-ID Component Character: Throughout this specification a character is meant to be interpreted as one Unicode code point. This also means that due to the structure of Unicode a character is not necessarily a full glyph but might be a combining accent or similar. Digital Media Object: A blob of raw bytes with some media type specific encoding. Extended Metadata: Metadata that is not encoded within the ISCC Meta-ID but may be supplied together with the ISCC . Generic Media Type: A basic content type such as plain text in a normalized and generic ( UTF-8 ) encoding format. ISCC : International Standard Content Code ISCC Code : The printable text encoded representation of an ISCC ISCC Digest : The raw binary data of an ISCC","title":"Definitions"},{"location":"specification/#introduction","text":"An ISCC permanently identifies content at multiple levels of granularity . It is algorithmically generated from basic metadata and the contents of a digital media object. It is designed for being registered and stored on a public and decentralized blockchain. An ISCC for a media object can be created and registered by the content author, a publisher, a service provider or anybody else. By itself the ISCC and its basic registration on a blockchain does not make any statement or claim about authorship or ownership of the identified content.","title":"Introduction"},{"location":"specification/#iscc-structure","text":"A Fully Qualified ISCC Digest is a fixed size sequence of 36 bytes (288 bits) assembled from multiple sub-components. The Fully Qualified ISCC Code is a 52 character encoded printable string representation of a complete ISCC Digest . This is a high-level overview of the ISCC creation process:","title":"ISCC Structure"},{"location":"specification/#iscc-components","text":"The ISCC Digest is built from multiple self-describing 72-bit components: Components: Meta-ID Content-ID Data-ID Instance-ID Context: Intangible creation Content similarity Data similarity Data checksum Input: Metadata Extracted content Raw data Raw data Algorithms: Similarity Hash Type specific CDC , Minimum Hash CDC , Hash Tree Size: 72 bits 72 bits 72 bits 72 bits ISCC components MAY be used separately or in combination by applications for various purposes. Individual components MUST be presented as 13- character base58-iscc encoded strings to end users and MAY be prefixed with their component name. Single component ISCC -Code (13 characters) Meta-ID : CCDFPFc87MhdT Combinations of components MUST include the Meta-ID component and MUST be ordered as Meta-ID , Content-ID , Data-ID , and Instance-ID . Individual components MAY be skipped and SHOULD be separated with hyphens. A combination of components SHOULD be prefixed with \" ISCC \". Combination of ISCC -Code components ISCC : CCPktvj3dVoVa-CTPCWTpGPMaLZ-CDL6QsUZdZzog A Fully Qualified ISCC Code is an ordered sequence of Meta-ID, Content-ID, Data-ID, and Instance-ID codes. It SHOULD be prefixed with ISCC and MAY be separated by hyphens. Fully Qualified ISCC -Code (52 characters) ISCC : CCDFPFc87MhdTCTWAGYJ9HZGj1CDhydSjutScgECR4GZ8SW5a7uc Fully Qualified ISCC -Code with hyphens (55 characters) ISCC : CCDFPFc87MhdT-CTWAGYJ9HZGj1-CDhydSjutScgE-CR4GZ8SW5a7uc","title":"ISCC Components"},{"location":"specification/#component-types","text":"Each component has the same basic structure of a 1-byte header and a 8-byte body section. The 1-byte header of each component is subdivided into 2 nibbles (4 bits). The first nibble specifies the component type while the second nibble is component specific. The header only needs to be carried in the encoded representation. As similarity searches across different components are of little use, the type information contained in the header of each component can be safely ignored after an ISCC has been decomposed and internally typed by an application.","title":"Component Types"},{"location":"specification/#list-of-component-headers","text":"Component Nibble-1 Nibble-2 Byte Code Meta-ID 0000 0000 - ISCC version 1 0x00 CC Content-ID-Text 0001 0000 - Content Type Text 0x10 CT Content-ID-Text PCF 0001 0001 - Content Type Text + PCF 0x11 Ct Content-ID-Image 0001 0010 - Content Type Image 0x12 CY Content-ID-Image PCF 0001 0011 - Content Type Image + PCF 0x13 Ci Content-ID-Audio 0001 0100 - Content Type Audio 0x14 CA Content-ID-Audio PCF 0001 0101 - Content Type Audio + PCF 0x15 Ca Content-ID-Video 0001 0110 - Content Type Video 0x16 CV Content-ID-Video PCF 0001 0111 - Content Type Video + PCF 0x17 Cv Content-ID-Mixed 0001 1000 - Content Type Mixed 0x18 CM Content-ID Mixed PCF 0001 1001 - Content Type Mixed + PCF 0x19 Cm Data-ID 0010 0000 - Reserved 0x20 CD Instance-ID 0011 0000 - Reserved 0x30 CR The body section of each component is specific to the component and always 8-bytes and can thus be fit into a 64-bit integer for efficient data processing. The following sections give an overview of how the different components work and how they are generated.","title":"List of Component Headers"},{"location":"specification/#meta-id-component","text":"The Meta-ID component starts with a 1-byte header 00000000 . The first nibble 0000 indicates that this is a Meta-ID component type. The second nibble 0000 indicates that it belongs to an ISCC of version 1. All subsequent components are expected to follow the specification of a version 1 ISCC . The Meta-ID body is built from a 64-bit similarity_hash over 4- character n-grams of the basic metadata of the content to be identified. The basic metadata supplied to the META-ID generating function is assumed to be UTF-8 encoded. Errors that occur during the decoding of such a bytestring input to a native Unicode MUST terminate the process and must not be silenced. An ISCC generating application MUST provide a meta_id function that accepts minimal and generic metadata and returns a Base58- ISCC encoded Meta-ID component and trimmed metadata.","title":"Meta-ID Component"},{"location":"specification/#inputs-to-meta-id-function","text":"Name Type Required Description title text Yes The title of an intangible creation. extra text No An optional short statement that distinguishes this intangible creation from another one for the purpose of Meta-ID uniqueness. (default: empty string) version integer No ISCC version number. (default: 0) Note The basic metadata inputs are intentionally simple and generic. We abstain from more specific metadata for Meta-ID generation in favor of compatibility across industries. Imagine a creators input-field for metadata. Who would you list as the creators of a movie? The directors, writers the main actors? Would you list some of them or if not how do you decide whom you will list. All disambiguation of similar title data can be accomplished with the extra-field. Industry- and application-specific metadata requirements can be supplied as extended metadata with ISCC registration.","title":"Inputs to Meta-ID function"},{"location":"specification/#generate-meta-id","text":"An ISCC generating application must follow these steps in the given order to produce a stable Meta-ID: Verify the requested ISCC version is supported by your implementation. Apply text_pre_normalize separately to the title and extra inputs. Apply text_trim to the results of step 1. The results of this step MUST be supplied as basic metadata for ISCC registration. Concatenate trimmed title and extra from using a space ( \\u0020 ) as a seperator. Apply text_normalize to the results of step 3. Create a list of 4 character n-grams by sliding character -wise through the result of step 4. Encode each n-gram from step 5 to an UTF-8 bytestring and calculate its xxHash64 digest. Apply similarity_hash to the list of digests from step 6. Prepend the 1-byte component header according to component type and ISCC version (e.g. 0x00 ) to the results of step 7. Encode the resulting 9 byte sequence with encode Return encoded Meta-ID, trimmed title and trimmed extra data. See also: Meta-ID reference code Text trimming When trimming text be sure to trim the byte-length of the UTF-8 encoded version and not the number of characters. The trim point MUST be such, that it does not cut into multibyte characters. Characters might have different UTF-8 byte-length. For example \u00fc is 2-bytes, \u9a69 is 3-bytes and \ud841\udf0e is 4-bytes. So the trimmed version of a string with 128 \u9a69 -characters will result in a 42- character string with a 126-byte UTF-8 encoded length. This is necessary because the results of this operation will be stored as basic metadata with strict byte size limits on the blockchain. Automated Data-Ingestion Applications that perform automated data-ingestion SHOULD apply a customized preliminary normalization to title data tailored to the dataset. Depending on catalog data removing pairs of brackets [], (), {}, and text in between them or cutting all text after the first occurence of a semicolon (;) or colon (:) can vastly improve deduplication.","title":"Generate Meta-ID"},{"location":"specification/#dealing-with-meta-id-collisions","text":"Ideally we want multiple ISCCs that identify different manifestations of the same intangible creation to be automatically grouped by an identical leading Meta-ID component. We call such a natural grouping an intended component collision . Metadata, captured and edited by humans, is notoriously unreliable. By using normalization and a similarity hash on the metadata we account for some of this variation while keeping the Meta-ID component somewhat stable. Auto-generated Meta-IDs components are expected to miss some intended collisions. An application SHOULD check for such missed intended component collisions before registering a new Meta-ID with the canonical registry of ISCCs by conducting a similarity search and asking for user feedback. But what about unintended component collisions ? Such collisions might happen because two different intangible creations have very similar or even identical metadata. But they might also happen simply by chance. With 2^56 possibile Meta-ID components the probability of random collisions rises in an S-curved shape with the number of deployed ISCCs (see: Hash Collision Probabilities ). We should keep in mind that, the Meta-ID component is only one part of a fully qualified ISCC Code . Unintended collisions of the Meta-ID component are generally deemed as acceptable and expected . If for any reason an application wants to avoid unintended collisions with pre-existing Meta-ID components it may utilize the extra -field. An application MUST first generate a Meta-ID without asking the user for input to the extra -field and then first check for collisions with the canonical registry of ISCCs. After it finds a collision with a pre-existing Meta-ID it may display the metadata of the colliding entry and interact with the user to determine if it indeed is an unintended collision. Only if the user indicates an unintended collision, may the application ask for a disambiguation that is then added as an amendment to the metadata via the extra -field to create a different Meta-ID component. The application may repeat the pre-existence check until it finds no collision or a user intended collision. The application MUST NOT supply auto-generated input to the extra -field. It is our opinion that the concept of intended collisions of Meta-ID components is generally useful concept and a net positive. But one must be aware that this characteristic also has its pitfalls. It is by no means an attempt to provide an unambiguous - agreed upon - definition of \"identical intangible creations\" .","title":"Dealing with Meta-ID collisions"},{"location":"specification/#content-id-component","text":"The Content-ID component has multiple subtypes. The subtypes correspond with the Generic Media Types ( GMT ) . A fully qualified ISCC can only have one Content-ID component of one specific GMT , but there may be multiple ISCCs with different Content-ID types per digital media object. A Content-ID is generated in two broad steps. In the first step, we extract and convert content from a rich media type to a normalized GMT . In the second step, we use a GMT -specific process to generate the Content-ID component of an ISCC .","title":"Content-ID Component"},{"location":"specification/#generic-media-types","text":"The Content-ID type is signaled by the first 3 bits of the second nibble of the first byte of the Content-ID: Conent-ID Type Nibble 2 Bits 0-3 Description text 000 Generated from extracted and normalized plain-text image 001 Generated from normalized grayscale pixel data audio 010 To be defined in later version of specification video 011 To be defined in later version of specification mixed 100 Generated from multiple Content-IDs 101, 110, 111 Reserved for future versions of specification","title":"Generic Media Types"},{"location":"specification/#content-id-text","text":"The Content-ID-Text is built from the extracted plain-text content of an encoded media object. To build a stable Content-ID-Text the plain-text content must first be extracted from the digital media object. It should be extracted in a way that is reproducible. There are many different text document formats out in the wilde and extracting plain-text from all of them is anything but a trivial task. While text-extraction is out of scope for this specification it is RECOMMENDED, that plain-text content SHOULD be extracted with the open-source Apache Tika v1.17 toolkit, if a generic reproducibility of the Content-ID-Text component is desired. An ISCC generating application MUST provide a content_id(text, partial=False) function that accepts UTF-8 encoded plain text and a boolean indicating the partial content flag as input and returns a Content-ID with GMT type text . The procedure to create a Content-ID-Text is as follows: Apply text_pre_normalize . Apply text_normalize to the text input. Split the normalized text into a list of words at whitespace boundaries. Create a list of 5 word shingles by sliding word-wise through the list of words. Create a list of 32-bit unsigned integer features by applying xxHash32 to results of step 4. Apply minimum_hash to the list of features from step 5. Collect the least significant bits from the 128 MinHash features from step 6. Create two 64-bit digests from the first and second half of the collected bits. Apply similarity_hash to the digests returned from step 8. Prepend the 1-byte component header ( 0x10 full content or 0x11 partial content). Encode and return the resulting 9-byte sequence with encode . See also: Content-ID-Text reference code","title":"Content-ID-Text"},{"location":"specification/#content-id-image","text":"For the Content-ID-Image we are opting for a DCT-based perceptual image hash instead of a more sophisticated keypoint detection based method. In view of the generic deployability of the ISCC we chose an algorithm that has moderate computation requirements and is easy to implement while still being robust against common image manipulations. An ISCC generating application MUST provide a content_id_image(image, partial=False) function that accepts a local file path to an image and returns a Content-ID with GMT type image . The procedure to create a Content-ID-Image is as follows: Apply image_normalize to receive a two-dimensional array of grayscale pixel data. Apply image_hash to the results of step 1. Prepend the 1-byte component header ( 0x12 full content or 0x13 partial content) to results of step 2. Encode and return the resulting 9-byte sequence with encode See also: Content-ID-Image reference code Image Data Input The content_id_image function may optionally accept the raw byte data of an encoded image or an internal native image object as input for convenience. JPEG Decoding Decoding of JPEG images is non-deterministic. Different image processing libraries may yield diverging pixel data and result in different Image-IDs. The reference implementation currently uses the builtin decoder of the Python Pillow imaging library. Future versions of the ISCC specification may define a custom deterministic JPEG decoding procedure.","title":"Content-ID-Image"},{"location":"specification/#content-id-mixed","text":"The Content-ID-Mixed aggregates multiple Content-IDs of the same or different types. It may be used for digital media objects that embed multiples types of media or for collections of contents of the same type. First we have to collect contents from the mixed media object or content collection and generate Content-IDs for each item. An ISCC conforming application must provide a content_id_mixed function that takes a list of Content-ID Codes as input and returns a Content-ID-Mixed. Follow these steps to create a Content-ID-Mixed: Signature: conent_id_mixed(cids: List[str], partial: bool=False) -> str Decode the list of Content-IDs. Extract the first 8-bytes from each digest ( Note : this includes the header part of the Content-IDs). Apply similarity_hash to the list of digests from step 2. Prepend the 1-byte component header( 0x18 full content or 0x19 partial content) Apply encode to the result of step 5 and return the result. See also: Content-ID-Mixed reference code","title":"Content-ID-Mixed"},{"location":"specification/#partial-content-flag-pcf","text":"The last bit of the header byte of the Content-ID is the \"Partial Content Flag\". It designates if the Content-ID applies to the full content or just some part of it. The PCF MUST be set as a 0 -bit ( full GMT -specific content ) by default. Setting the PCF to 1 enables applications to create multiple linked ISCCs of partial extracts of a content collection. The exact semantics of partial content are outside of the scope of this specification. Applications that plan to support partial Content-IDs MUST clearly define their semantics. PCF Linking Example Let's assume we have a single newspaper issue \"The Times - 03 Jan 2009\". You would generate one Meta-ID component with title \"The Times\" and extra \"03 Jan 2009\". The resulting Meta-ID component will be the grouping prefix in this szenario. We use a Content-ID-Mixed with PCF 0 (not partial) for the ISCC of the newspaper issue. We generate Data-ID and Instance-ID from the print PDF of the newspaper issue. To create an ISCC for a single extracted image that should convey context with the newspaper issue we reuse the Meta-ID of the newspaper issue and create a Content-ID-Image with PCF 1 (partial to the newspaper issue). For the Data-ID or Instance-ID of the image we are free to choose if we reuse those of the newspaper issue or create separate ones. The former would express strong specialization of the image to the newspaper issue (not likely to be useful out of context). The latter would create a stronger link to an eventual standalone ISCC of the image. Note that in any case the ISCC of the individual image retains links in both ways: Image is linked to the newspaper issue by identical Meta-ID component Image is linked to the standalone version of the image by identical Content-ID-Image body This is just one example that illustrates the flexibility that the PCF -Flag provides in concert with a grouping Meta-ID. With great flexibility comes great danger of complexity. Applications SHOULD do careful planning before using the PCF -Flag with internally defined semantics.","title":"Partial Content Flag (PCF)"},{"location":"specification/#data-id-component","text":"For the Data-ID that encodes data similarity we use a content defined chunking algorithm that provides some shift resistance and calculate the MinHash from those chunks. To accomodate for small files the first 100 chunks have a ~140-byte size target while the remaining chunks target ~ 6kb in size. The Data-ID is built from the raw encoded data of the content to be identified. An ISCC generating application MUST provide a data_id function that accepts the raw encoded data as input.","title":"Data-ID Component"},{"location":"specification/#generate-data-id","text":"Apply data_chunks to the raw encoded content data. For each chunk calculate the xxHash32 integer hash. Apply minimum_hash to the resulting list of 32-bit unsigned integers. Collect the least significant bits from the 128 MinHash features. Create two 64-bit digests from the first and second half of the collected bits. Apply similarity_hash to the results of step 5. Prepend the 1-byte component header (e.g. 0x20). Apply encode to the result of step 5 and return the result. See also: Data-ID reference code","title":"Generate Data-ID"},{"location":"specification/#instance-id-component","text":"The Instance-ID is built from the raw data of the media object to be identified and serves as checksum for the media object. The raw data of the media object is split into 64-kB data-chunks. Then we build a hash-tree from those chunks and use the truncated tophash (merkle root) as component body of the Instance-ID. To guard against length-extension attacks and second pre-image attacks we use double sha256 for hashing. We also prefix the hash input data with a 0x00 -byte for the leaf nodes hashes and with a 0x01 -byte for the internal node hashes. While the Instance-ID itself is a non-cryptographic checksum, the full tophash may be supplied in the extended metadata of an ISCC secure integrity verification is required. An ISCC generating application MUST provide a instance_id function that accepts the raw data file as input and returns an encoded Instance-ID and a full hex-encoded 256-bit tophash .","title":"Instance-ID Component"},{"location":"specification/#generate-instance-id","text":"Split the raw bytes of the encoded media object into 64-kB chunks. For each chunk calculate the sha256d of the concatenation of a 0x00 -byte and the chunk bytes. We call the resulting values leaf node hashes ( LNH ). Calculate the next level of the hash tree by applying sha256d to the concatenation of a 0x01 -byte and adjacent pairs of LNH values. If the length of the list of LNH values is uneven concatenate the last LNH value with itself. We call the resulting values internal node hashes ( INH ). Recursively apply 0x01 -prefixed pairwise hashing to the results of step 3 until the process yields only one hash value. We call this value the tophash . Trim the resulting tophash to the first 8 bytes. Prepend the 1-byte component header (e.g. 0x30 ). Encode resulting 9-byte sequence with encode to an Instance-ID Code Hex-Encode the tophash Return the Intance-ID and the hex-encoded tophash See also: Instance-ID reference code Applications may carry, store, and process the leaf node hashes for advanced streaming data identification or partial data integrity verification.","title":"Generate Instance-ID"},{"location":"specification/#iscc-metadata","text":"As a generic content identifier the ISCC makes minimal assumptions about metadata that must or should be supplied together with an ISCC . The RECOMMENDED data-interchange format for ISCC metadata is JSON . We distinguish between Basic Metadata and Extended Metadata :","title":"ISCC Metadata"},{"location":"specification/#basic-metadata","text":"Basic metadata for an ISCC is metadata that is explicitly defined by this specification. The following table enumerates basic metadata fields for use in the top-level of the JSON metadata object: Name Type Required Description version integer No Version of ISCC Specification. Assumed to be 1 if omitted. title text Yes The title of an intangible creation identified by the ISCC . The normalized and trimmed UTF-8 encoded text MUST not exceed 128 Bytes. The result of processing title and extra data with the meta_id function MUST match the Meta-ID component of the ISCC . extra text No An optional short statement that distinguishes this intangible creation from another one for the purpose of Meta-ID uniqueness. tophash text (hex) No The full hex-encoded tophash (merkle root) returned by the instance_id function. meta array No A list of one or more extended metadata entries. Must include at least one entry if specified. Attention Depending on adoption and real world use, future versions of this specification may define new basic metadata fields. Applications MAY add custom fields at the top level of the JSON object but MUST prefix those fields with an underscore to avoid collisions with future extensions of this specification.","title":"Basic Metadata"},{"location":"specification/#extended-metadata","text":"Extended metadata for an ISCC is metadata that is not explicitly defined by this specification. All such metadata SHOULD be supplied as JSON objects within the top-level meta array field. This allows for a flexible and extendable way to supply additional industry specific metadata about the identified content. Extended metadata entries MUST be wrapped in JSON object of the following structure: Name Description schema The schema -field may indicate a well known metadata schema (such as Dublin Core, IPTC, ID3v2, ONIX) that is used. RECOMMENDED schema : \" schema.org \" mediatype The mediatype -field specifies an IANA Media Type . RECOMMENDED mediatype : \"application/ld+json\" url An URL that is expected to host the metadata with the indicated schema and mediatype . This field is only required if the data -field is omitted. data The data -field holds the metadata conforming to the indicated schema and mediatype. It is only required if the url field is omitted.","title":"Extended Metadata"},{"location":"specification/#iscc-registration","text":"The ISCC is a decentralized identifier. ISCCs can be generated for content by anybody who has access to the content. Due to the clustering properties of its components the ISCC provides utility in data interchange and de-duplication scenarios even without a global registry. There is no central authority for the registration of ISCC identifiers or certification of content authorship. As an open system the ISCC allows any person or organization to offer ISCC registration services as they see fit and without the need to ask anyone for permission. This also presumes that no person or organization may claim exclusive authority about ISCC registration.","title":"ISCC Registration"},{"location":"specification/#blockchain-registry","text":"A well known, decentralized, open, and public registry for canonical discoverability of ISCC identified content is of great value. For this reason it is RECOMMENDED to register ISCC identifiers on the open iscc data-stream of the Content Blockchain . For details please refer to the ISCC -Stream specification of the Content Blockchain.","title":"Blockchain Registry"},{"location":"specification/#iscc-embedding","text":"Embedding ISCC codes into content is only RECOMMENDED if it does not create a side effect. We call it a side effect if embedding an ISCC code modifies the content to such an extent, that it yields a different ISCC code. Side effects will depend on the combination of ISCC components that are to be embedded. A Meta-ID can always be embedded without side effect because it does not depend on the content itself. Content-ID and Data-ID may not change if embedded in larger media objects. Instance-IDs cannot easily be embedded as they will inevitably have a side effect on the post-embedding Instance-ID without special processing. Applications MAY embed ISCC codes that have side effects if they specify a procedure by which the embedded ISCC codes can be stripped in such a way that the stripped content will yield the original embedded ISCC codes. ISCC Embedding We are able to embed the following combination of components from the markdown version of this document into the document itself because adding or removing them has no side effect: ISCC : CCDbMYw6NfC8a-CTfLV4GoxGh7f-CDLmtRpZGVJhU","title":"ISCC Embedding"},{"location":"specification/#iscc-uri-scheme","text":"The purpose of the ISCC URI scheme based on RFC 3986 is to enable users to easily discover information like metadata or license offerings about a ISCC marked content by simply clicking a link on a webpage or by scanning a QR-Code. The scheme name is iscc . The path component MUST be a fully qualified ISCC Code without hyphens. An optional stream query key MAY indicate the blockchain stream information source. If the stream query key is omitted applications SHOULD return information from the open ISCC Stream . The scheme name component (\"iscc:\") is case-insensitive. Applications MUST accept any combination of uppercase and lowercase letters in the scheme name. All other URI components are case-sensitive. Applications MAY register themselves as handler for the \"iscc:\" URI scheme if no other handler is already registered. If another handler is already registered an application MAY ask the user to change it on the first run of the application.","title":"ISCC URI Scheme"},{"location":"specification/#uri-syntax","text":"<foo> means placeholder, [bar] means optional. iscc:<fq-iscc-code>[?stream=<name>]","title":"URI Syntax"},{"location":"specification/#uri-example","text":"iscc:11TcMGvUSzqoM1CqVA3ykFawyh1R1sH4Bz8A1of1d2Ju4VjWt26S?stream=smart-license","title":"URI Example"},{"location":"specification/#procedures-algorithms","text":"","title":"Procedures &amp; Algorithms"},{"location":"specification/#base58-iscc","text":"The ISCC uses a custom per-component data encoding similar to the zbase62 encoding by Zooko Wilcox-O'Hearn but with a 58- character symbol table. The encoding does not require padding and will always yield component codes of 13 characters length for ths 72-bit component digests. The predictable size of the encoding is a property that allows for easy composition and decomposition of components without having to rely on a delimiter (hyphen) in the ISCC code representation. Colliding body segments of the digest are preserved by encoding the header and body separately. The ASCII symbol table also minimizes transcription and OCR errors by omitting the easily confused characters 'O', '0', 'I', 'l' and is shuffled to generate human readable component headers. Symbol table SYMBOLS = \"C23456789rB1ZEFGTtYiAaVvMmHUPWXKDNbcdefghLjkSnopRqsJuQwxyz\"","title":"Base58-ISCC"},{"location":"specification/#encode","text":"Signature: encode(digest: bytes) -> str The encode function accepts a 9-byte ISCC Component Digest and returns the Base58- ISCC encoded alphanumeric string of 13 characters which we call the ISCC -Component Code . See also: Base- ISCC Encoding reference code","title":"encode"},{"location":"specification/#decode","text":"Signature: decode(code: str) -> bytes the decode function accepts a 13- character ISCC -Component Code and returns the corresponding 9-byte ISCC -Component Digest . See also: Base- ISCC Decoding reference code","title":"decode"},{"location":"specification/#content-normalization","text":"The ISCC standardizes some content normalization procedures to support reproducible and stable identifiers. Following the list of normalization functions that MUST be provided by a conforming implementation.","title":"Content Normalization"},{"location":"specification/#text_pre_normalize","text":"Signature: text_pre_normalize(text: str|bytes) -> str Decodes raw plain-text data and applies Unicode Normalization Form KC (NFKC) . The plain-text data MUST be stripped of any markup beforehand. Text input is expected to be UTF-8 encoded plain-text data or a native type of the implementing programming language that supports Unicode. Text decoding errors MUST fail with an error. See also: Text pre-normalization reference code","title":"text_pre_normalize"},{"location":"specification/#text_trim","text":"Signature: text_trim(text: str) -> str Trim text such that its UTF-8 encoded byte representation does not exceed 128-bytes each. See also: Text trimming reference code","title":"text_trim"},{"location":"specification/#text_normalize","text":"Signature: text_normalize(text: str) -> str We define a text normalization function that is specific to our application. It takes unicode text as an input and returns normalized Unicode text for further algorithmic processing. The text_normalize function performs the following operations in the given order while each step works with the results of the previous operation: Decompose the input text by applying Unicode Normalization Form D (NFD) . Filter and normalize text by iterating over unicode characters while: replacing groups of one or more consecutive Separator characters ( Unicode categories Zs, Zl and Zp) with exactly one Unicode SPACE character ( U+0020 ) . removing characters that are not in one of the Unicode categories Separator , Letter , Number or Symbol . converting characters to lowercase. Remove any leading or trailing Separator characters. Re-Compose the text by applying Unicode Normalization Form C (NFC) . See also: Text normalization reference code","title":"text_normalize"},{"location":"specification/#image_normalize","text":"Signature: image_normalize(img) -> List[List[int]] Accepts a file path, byte-stream or raw binary image data and MUST at least support JPEG, PNG, and GIF image formats. Normalize the image with the following steps: Convert the image to grayscale Resize the image to 32x32 pixels using bicubic interpolation Create a 32x32 two-dimensional array of 8-bit grayscale values from the image data See also: Image normalization reference code","title":"image_normalize"},{"location":"specification/#feature-hashing","text":"The ISCC standardizes various feature hashing algorithms that reduce content features to a binary vector used as the body of the various Content-ID components.","title":"Feature Hashing"},{"location":"specification/#similarity_hash","text":"Signature: similarity_hash(hash_digests: Sequence[ByteString]) -> bytes The similarity_hash function takes a sequence of hash digests which represent a set of features. Each of the digests MUST be of equal size. The function returns a new hash digest (raw 8-bit bytes) of the same size. For each bit in the input hashes calculate the number of hashes with that bit set and subtract the the count of hashes where it is not set. For the output hash set the same bit position to 0 if the count is negative or 1 if it is zero or positive. The resulting hash digest will retain similarity for similar sets of input hashes. See also [Charikar2002] . See also: Similarity hash reference code","title":"similarity_hash"},{"location":"specification/#minimum_hash","text":"Signature: minimum_hash(features: Iterable[int]) -> List[int] The minimum_hash function takes an arbitrary sized set of 32-bit integer features and reduces it to a fixed size vector of 128 features such that it preserves similarity with other sets. It is based on the MinHash implementation of the datasketch library by Eric Zhu . See also: Minimum hash reference code","title":"minimum_hash"},{"location":"specification/#image_hash","text":"Signature: image_hash(pixels: List[List[int]]) -> bytes Perform a discrete cosine transform per row of input pixels. Perform a discrete cosine transform per column on the resulting matrix from step 2. Extract upper left 8x8 corner of array from step 2 as a flat list. Calculate the median of the results from step 3. Create a 64-bit digest by iterating over the values of step 5 and setting a 1 - for values above median and 0 for values below or equal to median. Return results from step 5. See also: Image hash reference code","title":"image_hash"},{"location":"specification/#content-defined-chunking","text":"For shift resistant data chunking the ISCC requires a custom chunking algorithm:","title":"Content Defined Chunking"},{"location":"specification/#data_chunks","text":"Signature: data_chunks(data: stream) -> Iterator[bytes] The data_chunks function accepts a byte-stream and returns variable sized chunks. Chunk boundaries are determined by a gear based chunking algorithm based on [WenXia2016] . See also: CDC reference code","title":"data_chunks"},{"location":"specification/#conformance-testing","text":"An application that claims ISCC conformance MUST pass the ISCC conformance test suite. The test suite is available as json data in our Github Repository . Test Data is structured as follows: { \"<function_name>\" : { \"<test_name>\" : { \"inputs\" : [ \"<value1>\" , \"<value2>\" ], \"outputs\" : [ \"value1>\" , \"<value2>\" ] } } } Outputs that are expected to be raw bytes are embedded as HEX encoded strings in JSON and prefixed with hex: to support automated decoding during implementation testing. Example Byte outputs in JSON testdata: { \"data_chunks\": { \"test_001_cat_jpg\": { \"inputs\": [\"cat.jpg\"], \"outputs\": [\"hex:ffd8ffe1001845786966000049492a0008\", ...] } } }","title":"Conformance Testing"},{"location":"specification/#license","text":"Copyright \u00a9 2016 - 2018 Content Blockchain Project This work is licensed under a Creative Commons (CC BY-NC-SA 4.0) .","title":"License"}]}